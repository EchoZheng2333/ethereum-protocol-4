---
timezone: UTC+8
---

> 请在上边的 timezone 添加你的当地时区(UTC)，这会有助于你的打卡状态的自动化更新，如果没有添加，默认为北京时间 UTC+8 时区


# 你的名字

1. 自我介绍
区块链开发,最近在做一些Ethereum 客户端性能优化的工作.
2. 你认为你会完成本次残酷学习吗？
会
3. 你的联系方式（推荐 Telegram）
@lido33

## Notes

<!-- Content_START -->

### 2025.06.16

使用jsoniter流式解析提升erigon3加载大genesis的性能 [PR](https://github.com/OpenFusionist/erigon/tree/feat/jsoniter-stream_try2-ReadObjectCBWithoutCopy)


### 2025.06.17
[EIP-6110](https://eips.ethereum.org/EIPS/eip-6110) 减少了验证者质押流程的耗时:

before :`ETH1_FOLLOW_DISTANCE(minimum of 2048 ETH1 blocks, ~8 hours, to ensure stability of the chain) + EPOCHS_PER_ETH1_VOTING_PERIOD (64 epochs, ~6.8 hours, to organize a sizable committee for voting)`

now: 13min(?how to calc ~ 2 epoch for finialized)

TLDR; 存在一个过渡期, 升级前还未被beacon chain处理的deposit按照老的投票方式处理,过渡期结束的标志`state.eth1_deposit_index == state.deposit_requests_start_index`  也就是当信标链已经处理过的来自以太坊 1.0 (执行层) 存款合约的存款事件的总数等于升级后发送的第一个deposit index, eth1vote 被弃用 ref:https://eips.ethereum.org/EIPS/eip-6110#consensus-layer

### 2025.06.18

**erigon  state 写入流程**

4 个阶段：

1. EVM 执行阶段（In-memory 更新）  
2. Aggregator 写缓存阶段（Writer 收集）  
3. Flush & Collate 阶段（把 WAL 合并成 Segment 文件）  
4. Build & Integrate 阶段（生成索引并挂到可见文件链）

------------------------------------------------------------------
一、EVM 执行阶段 —— IntraBlockState／stateObject  
------------------------------------------------------------------
• `state.(*IntraBlockState).FinalizeTx`  
  - 交易执行结束，调用 `FinalizeTx` 把本次 TX 对账户和 Storage 的修改“固化”到 `state.StateDB` 的中间层。  

• `state.updateAccount / state.(*stateObject).updateStorage`  
  - 这两步把账户余额、nonce、代码哈希、Storage 等字段刷到 **stateObject** 中的 dirty 字段。  
  - 这里的更新还停留在内存，尚未与聚合器（Aggregator）交互。

------------------------------------------------------------------
二、Aggregator 写缓存阶段 —— Writer / DomainBufferedWriter  
------------------------------------------------------------------
• `state.(*Writer).WriteAccountStorage`  
  - 这是聚合器对外暴露的“把一条账户或 Storage 记录写入磁盘前缓存”的统一入口。  
  - 内部先定位到对应的 **Domain**（Account / Storage / Code / Commitment 等），随后调用

• `state.(*temporalPutDel).DomainPut`  
  - 该结构负责“本轮（一个 aggregationStep）内的增删改”暂存；  
  - 继续往下会进入 `state.(*SharedDomains).writeAccountStorage`，将键值放进

• `state.(*DomainBufferedWriter).addValue`  
  - 真正往 `d.values` 这个 `etl.Collector` 里 `Collect(k, v)`，形成 WAL（write-ahead-log）文件。  
  - 同时把上一个版本写到 History：`historyBufferedWriter.AddPrevValue`。  
  - 这一步还没有磁盘落地，只是把数据写进临时目录下的 *sortable buffer*。

------------------------------------------------------------------
三、Flush & Collate 阶段 —— dumpStepRangeOnDisk / collateETL  
------------------------------------------------------------------
当达到 aggregationStep（默认 1 M TX、高度或者时间窗口）或主动 `Flush` 时：

1. `DomainBufferedWriter.Flush`  
   - 把 `etl.Collector` 缓冲区刷出，调用 `collector.Load()` 把所有 `(k, ^step | value)` 扫一遍。  

2. `Domain.dumpStepRangeOnDisk`  
   - 根据本次要刷新的 `[stepFrom, stepTo)` 创建 `Collation`：  
     • 每个 Domain 单独生成 `.kv` 原始数据 segment；  
     • History 另外生成 `.ef` / `.v`。  

3. `collateETL`  
   - 把 WAL 里的 KV 按 key 排序后依次写入 `seg.Compressor`，形成压缩/未压缩数据块。  
   - 大 Value（如 Code）走 “key+step → value”；小 Value 走 “key → step|value”。

------------------------------------------------------------------
四、Build & Integrate 阶段 —— buildFileRange / integrateDirtyFiles  
------------------------------------------------------------------
1. `Domain.buildFileRange`  
   a. `.kv` 写完后先 `Compress()`，生成只读的 `seg.Decompressor`;  
   b. 对不同 Accessor 选项生成索引：  
      • Hash-map (`.kvi`) —— 用 `recsplit` 构建 MPH；  
      • B-Tree   (`.bt`) —— 用自研 2-level B-Tree；  
      • Bloom    (`.kvei`)—— existence filter。  

2. `Domain.integrateDirtyFiles`  
   - 把刚生产的 `FilesItem` 放进 `d.dirtyFiles` 树；  
   - 随后调用 `reCalcVisibleFiles`，重新计算 **_visible** 文件切片：  
     • 保证没有重叠区间、保证只含“可见且最新”的文件；  
     • 把可见文件暴露给只读查询 (`BeginFilesRo`)。

至此，写入流程完成：  
• 最新值已经在 `.kv` segment 中；  
• 历史差分在 `.ef`/`.v`；  
• 对应索引和布隆过滤器也就绪，下一轮查询可直接命中文件而不需走 MDBX。

------------------------------------------------------------------
关键对象对照
------------------------------------------------------------------
① Domain（account / storage / code / commitment …）  
   • 管理同名 `.kv` 文件及其索引；  
   • 持有一个 **History** 子结构（keys & inverted-index）。  

② DomainBufferedWriter  
   • 每次 Put/Delete 写入 Collector；  
   • 负责把“上一个版本”写到 History。  

③ FilesItem  
   • 对应一个 `[startTxNum, endTxNum)` 范围的 segment + 索引；  
   • 通过 `dirtyFiles` 与 `_visible.files` 区分“全部”和“可用”。  

④ etl.Collector  
   • 类似外部归并排序的桶：先写临时 sortable buffer，再统一 flush & sort。

通过以上 4 个阶段，Erigon 把高并发的状态写操作拆分为「内存→WAL→排序→压缩→只读 Segment」流水线，大幅降低了 MDBX 的随机写放大，也为后续冷热分层与并发查询做好了准备。

### 2025.06.19

整理了一个erigon PR: optimize: reduce sortedAllocKeys memory allocations #15628

### 2025.06.20

继续回顾了下pectra 升级相关的几个EIP:
EIP-7251: Increase the MAX_EFFECTIVE_BALANCE
EIP-7002: Execution layer triggerable exits

<!-- Content_END -->
